{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense,Attention,GlobalMaxPooling1D,GlobalAveragePooling1D\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from keras.preprocessing.text import Tokenizer,text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import AveragePooling1D,Bidirectional, Conv1D,MaxPooling1D,Embedding, LSTM, Input, Flatten, Dense, Dropout, Convolution2D, Conv2D, MaxPooling2D, Lambda, GlobalMaxPooling2D, GlobalAveragePooling2D, BatchNormalization, Activation, AveragePooling2D, Concatenate\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import Flatten,Layer\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras import layers, models, optimizers,activations,initializers,regularizers,constraints\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "df= pd.read_csv('/Users/yuwenyu/Desktop/PhD./fake_news/Constraint_English_Train.csv')\n",
    "df_val= pd.read_csv('/Users/yuwenyu/Desktop/PhD./fake_news/Constraint_English_Val.csv')\n",
    "df_test= pd.read_csv('/Users/yuwenyu/Desktop/PhD./fake_news/Constraint_English_Test.csv')\n",
    "\n",
    "#df= pd.read_csv('Constraint_English_Train.csv')\n",
    "#df_val= pd.read_csv('fake_news/Constraint_English_Val.csv')\n",
    "#df_test= pd.read_csv('Constraint_English_Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.concat([df, df_val])\n",
    "X_train=df_all['tweet']\n",
    "y_train=df_all['label']\n",
    "X_test= df_test['tweet']\n",
    "y_test=df_test['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding label\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test= encoder.fit_transform(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "tokenizer.fit_on_texts(X_test)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "input_length=256 #1420\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=input_length)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=input_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27418\n"
     ]
    }
   ],
   "source": [
    "#word embedding\n",
    "emb_dim=300\n",
    "vocab=len(tokenizer.word_index)+1\n",
    "#print(vocab)\n",
    "\n",
    "emb_mat= np.zeros((vocab,emb_dim))\n",
    "\n",
    "with open('/Users/yuwenyu/Desktop/PhD./fake_news/glove.6B.300d.txt') as f:\n",
    "    for line in f:\n",
    "        word,*emb = line.split()\n",
    "        if word in tokenizer.word_index:\n",
    "            ind=tokenizer.word_index[word]\n",
    "            emb_mat[ind]=np.array(emb,dtype=\"float32\")[:emb_dim]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab,300,weights=[emb_mat], input_length=input_length,trainable=False))\n",
    "model.add(Bidirectional(LSTM(300, return_sequences=True)))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=100))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "history=model.fit(X_train,y_train,epochs=10,batch_size=256, verbose=2,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final evaluation of the model\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "y_pred=model.predict(X_test)\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred, labels=[1,0], digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
